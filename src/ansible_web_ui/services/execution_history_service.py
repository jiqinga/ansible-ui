"""
æ‰§è¡Œå†å²è®°å½•æœåŠ¡

æä¾›Ansibleä»»åŠ¡æ‰§è¡Œå†å²çš„æŸ¥è¯¢ã€åˆ†é¡µã€ç­›é€‰å’Œæ—¥å¿—ç®¡ç†åŠŸèƒ½ã€‚
"""

import os
import json
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Any, Tuple
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, desc, asc, and_, or_, text
from sqlalchemy.orm import selectinload

from ansible_web_ui.models.task_execution import TaskExecution, TaskStatus
from ansible_web_ui.models.user import User
from ansible_web_ui.services.base import BaseService
from ansible_web_ui.core.config import get_settings
from ansible_web_ui.core.cache import cached
from sqlalchemy import case


class ExecutionHistoryService(BaseService[TaskExecution]):
    """
    æ‰§è¡Œå†å²è®°å½•æœåŠ¡ç±»
    
    ä¸“é—¨å¤„ç†ä»»åŠ¡æ‰§è¡Œå†å²çš„æŸ¥è¯¢ã€åˆ†é¡µã€ç­›é€‰å’Œæ—¥å¿—ç®¡ç†ã€‚
    """
    
    def __init__(self, db_session: AsyncSession):
        super().__init__(TaskExecution, db_session)
        self.settings = get_settings()
    
    @cached(ttl=60, key_prefix="history_stats")
    async def get_statistics(self, period: str = "today") -> Dict[str, Any]:
        """
        è·å–æ‰§è¡Œå†å²ç»Ÿè®¡ï¼ˆé«˜åº¦ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        
        ğŸš€ ä¼˜åŒ–ç­–ç•¥:
        1. ä½¿ç”¨å•ä¸ªæŸ¥è¯¢è·å–æ‰€æœ‰ç»Ÿè®¡æ•°æ®
        2. åˆ©ç”¨æ•°æ®åº“ç´¢å¼•
        3. å‡å°‘Pythonç«¯è®¡ç®—
        
        Args:
            period: ç»Ÿè®¡å‘¨æœŸï¼ˆtoday/week/monthï¼‰
            
        Returns:
            Dict[str, Any]: ç»Ÿè®¡æ•°æ®
        """
        # è®¡ç®—æ—¶é—´èŒƒå›´
        now = datetime.utcnow()
        if period == "today":
            start_time = now.replace(hour=0, minute=0, second=0, microsecond=0)
        elif period == "week":
            start_time = now - timedelta(days=7)
        elif period == "month":
            start_time = now - timedelta(days=30)
        else:
            start_time = now - timedelta(days=1)
        
        # ğŸš€ å•ä¸ªæŸ¥è¯¢è·å–æ‰€æœ‰ç»Ÿè®¡
        result = await self.db.execute(
            select(
                func.count().label("total"),
                func.count(case((TaskExecution.status == "success", 1))).label("success"),
                func.count(case((TaskExecution.status == "failed", 1))).label("failed"),
                func.count(case((TaskExecution.status == "running", 1))).label("running"),
                func.avg(
                    case((
                        TaskExecution.status == "success",
                        TaskExecution.duration
                    ))
                ).label("avg_duration")
            )
            .where(TaskExecution.created_at >= start_time)
        )
        
        row = result.first()
        total = row.total or 0
        success = row.success or 0
        failed = row.failed or 0
        running = row.running or 0
        avg_duration = row.avg_duration or 0
        
        return {
            "period": period,
            "total_executions": total,
            "successful": success,
            "failed": failed,
            "running": running,
            "success_rate": round((success / total * 100) if total > 0 else 0, 1),
            "average_duration_seconds": round(avg_duration, 1)
        }
    
    @cached(ttl=300, key_prefix="history_trends")
    async def get_trends(self, days: int = 7) -> List[Dict[str, Any]]:
        """
        è·å–æ‰§è¡Œè¶‹åŠ¿ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        
        ğŸš€ ä¼˜åŒ–ç­–ç•¥:
        1. ä½¿ç”¨æ•°æ®åº“æ—¥æœŸå‡½æ•°åˆ†ç»„
        2. å•æ¬¡æŸ¥è¯¢è·å–æ‰€æœ‰æ•°æ®
        3. å‡å°‘æ•°æ®ä¼ è¾“é‡
        
        Args:
            days: å¤©æ•°
            
        Returns:
            List[Dict[str, Any]]: è¶‹åŠ¿æ•°æ®
        """
        start_date = datetime.utcnow() - timedelta(days=days)
        
        # ğŸš€ ä½¿ç”¨æ•°æ®åº“åˆ†ç»„å’Œèšåˆ
        result = await self.db.execute(
            select(
                func.date(TaskExecution.created_at).label("date"),
                func.count().label("total"),
                func.count(case((TaskExecution.status == "success", 1))).label("success"),
                func.count(case((TaskExecution.status == "failed", 1))).label("failed")
            )
            .where(TaskExecution.created_at >= start_date)
            .group_by(func.date(TaskExecution.created_at))
            .order_by(func.date(TaskExecution.created_at))
        )
        
        return [
            {
                "date": str(row.date),
                "total": row.total,
                "success": row.success,
                "failed": row.failed,
                "success_rate": round((row.success / row.total * 100) if row.total > 0 else 0, 1)
            }
            for row in result.all()
        ]
    
    @cached(ttl=30, key_prefix="recent_executions")
    async def get_recent_executions(
        self, 
        limit: int = 8,
        sort_by: str = "created_at",
        sort_order: str = "desc"
    ) -> List[Dict[str, Any]]:
        """
        è·å–æœ€è¿‘æ‰§è¡Œè®°å½•ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        
        ğŸš€ ä¼˜åŒ–ç­–ç•¥:
        1. åªæŸ¥è¯¢å¿…è¦å­—æ®µ
        2. ä½¿ç”¨ç´¢å¼•ä¼˜åŒ–æ’åº
        3. é™åˆ¶è¿”å›æ•°é‡
        
        Args:
            limit: é™åˆ¶æ•°é‡
            sort_by: æ’åºå­—æ®µ
            sort_order: æ’åºæ–¹å‘
            
        Returns:
            List[Dict[str, Any]]: æ‰§è¡Œè®°å½•åˆ—è¡¨
        """
        # ğŸš€ åªæŸ¥è¯¢éœ€è¦çš„å­—æ®µï¼Œå‡å°‘æ•°æ®ä¼ è¾“
        query = select(
            TaskExecution.id,
            TaskExecution.task_id,
            TaskExecution.playbook_name,
            TaskExecution.status,
            TaskExecution.created_at,
            TaskExecution.completed_at,
            TaskExecution.user_id
        )
        
        # æ’åº
        sort_field = getattr(TaskExecution, sort_by, TaskExecution.created_at)
        if sort_order == "desc":
            query = query.order_by(desc(sort_field))
        else:
            query = query.order_by(sort_field)
        
        query = query.limit(limit)
        
        result = await self.db.execute(query)
        
        return [
            {
                "id": row.id,
                "task_id": row.task_id,
                "playbook_name": row.playbook_name,
                "status": row.status,
                "created_at": row.created_at.isoformat(),
                "completed_at": row.completed_at.isoformat() if row.completed_at else None,
                "user_id": row.user_id,
                "duration_seconds": (
                    (row.completed_at - row.created_at).total_seconds()
                    if row.completed_at else None
                )
            }
            for row in result.all()
        ]

    async def get_execution_history(
        self,
        skip: int = 0,
        limit: int = 20,
        user_id: Optional[int] = None,
        status: Optional[TaskStatus] = None,
        playbook_name: Optional[str] = None,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        search_term: Optional[str] = None,
        sort_by: str = "created_at",
        sort_order: str = "desc"
    ) -> Tuple[List[TaskExecution], int]:
        """
        è·å–æ‰§è¡Œå†å²è®°å½•ï¼ˆæ”¯æŒåˆ†é¡µå’Œç­›é€‰ï¼‰
        
        Args:
            skip: è·³è¿‡çš„è®°å½•æ•°
            limit: é™åˆ¶è¿”å›çš„è®°å½•æ•°
            user_id: ç”¨æˆ·IDç­›é€‰
            status: çŠ¶æ€ç­›é€‰
            playbook_name: Playbookåç§°ç­›é€‰
            start_date: å¼€å§‹æ—¥æœŸç­›é€‰
            end_date: ç»“æŸæ—¥æœŸç­›é€‰
            search_term: æœç´¢å…³é”®è¯
            sort_by: æ’åºå­—æ®µ
            sort_order: æ’åºæ–¹å‘ï¼ˆasc/descï¼‰
            
        Returns:
            Tuple[List[TaskExecution], int]: (å†å²è®°å½•åˆ—è¡¨, æ€»è®°å½•æ•°)
        """
        # æ„å»ºåŸºç¡€æŸ¥è¯¢
        query = select(TaskExecution).options(
            selectinload(TaskExecution.user)
        )
        count_query = select(func.count(TaskExecution.id))
        
        # åº”ç”¨ç­›é€‰æ¡ä»¶
        conditions = []
        
        if user_id:
            conditions.append(TaskExecution.user_id == user_id)
        
        if status:
            conditions.append(TaskExecution.status == status)
        
        if playbook_name:
            conditions.append(TaskExecution.playbook_name.ilike(f"%{playbook_name}%"))
        
        if start_date:
            conditions.append(TaskExecution.created_at >= start_date)
        
        if end_date:
            conditions.append(TaskExecution.created_at <= end_date)
        
        if search_term:
            # åœ¨å¤šä¸ªå­—æ®µä¸­æœç´¢
            search_conditions = [
                TaskExecution.playbook_name.ilike(f"%{search_term}%"),
                TaskExecution.inventory_targets.ilike(f"%{search_term}%"),
                TaskExecution.task_id.ilike(f"%{search_term}%")
            ]
            conditions.append(or_(*search_conditions))
        
        # åº”ç”¨æ‰€æœ‰æ¡ä»¶
        if conditions:
            query = query.where(and_(*conditions))
            count_query = count_query.where(and_(*conditions))
        
        # åº”ç”¨æ’åº
        sort_field = getattr(TaskExecution, sort_by, TaskExecution.created_at)
        if sort_order.lower() == "desc":
            query = query.order_by(desc(sort_field))
        else:
            query = query.order_by(asc(sort_field))
        
        # åº”ç”¨åˆ†é¡µ
        query = query.offset(skip).limit(limit)
        
        # æ‰§è¡ŒæŸ¥è¯¢
        result = await self.db.execute(query)
        executions = result.scalars().all()
        
        # è·å–æ€»æ•°
        count_result = await self.db.execute(count_query)
        total_count = count_result.scalar()
        
        return executions, total_count

    async def get_execution_detail(self, task_id: str) -> Optional[TaskExecution]:
        """
        è·å–æ‰§è¡Œè¯¦æƒ…ï¼ˆåŒ…å«å…³è”çš„ç”¨æˆ·ä¿¡æ¯ï¼‰
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            Optional[TaskExecution]: ä»»åŠ¡æ‰§è¡Œè¯¦æƒ…æˆ–None
        """
        result = await self.db.execute(
            select(TaskExecution)
            .options(selectinload(TaskExecution.user))
            .where(TaskExecution.task_id == task_id)
        )
        return result.scalar_one_or_none()

    async def get_execution_log_content(self, task_id: str) -> Optional[str]:
        """
        è·å–æ‰§è¡Œæ—¥å¿—å†…å®¹
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            Optional[str]: æ—¥å¿—å†…å®¹æˆ–None
        """
        execution = await self.get_execution_detail(task_id)
        if not execution or not execution.log_file_path:
            return None
        
        try:
            # ç¡®ä¿æ—¥å¿—æ–‡ä»¶è·¯å¾„å®‰å…¨
            log_path = os.path.abspath(execution.log_file_path)
            logs_dir = os.path.abspath(self.settings.LOGS_DIR)
            
            if not log_path.startswith(logs_dir):
                return None
            
            if os.path.exists(log_path):
                with open(log_path, 'r', encoding='utf-8') as f:
                    return f.read()
        except Exception:
            pass
        
        return None

    async def get_today_statistics_fast(self) -> Dict[str, Any]:
        """
        å¿«é€Ÿè·å–ä»Šæ—¥ç»Ÿè®¡ï¼ˆä¸“é—¨ä¼˜åŒ–çš„æŸ¥è¯¢ï¼‰
        
        ä¼˜åŒ–ç‚¹:
        1. ä½¿ç”¨ DATE('now') ç›´æ¥åŒ¹é…ä»Šå¤©
        2. ä¸ä½¿ç”¨ GROUP BYï¼Œç›´æ¥èšåˆ
        3. å•æ¬¡æŸ¥è¯¢è·å–æ‰€æœ‰æ•°æ®
        
        Returns:
            Dict[str, Any]: ä»Šæ—¥ç»Ÿè®¡æ•°æ®
        """
        # ä¼˜åŒ–çš„å•æ¬¡æŸ¥è¯¢ï¼Œç›´æ¥è·å–ä»Šæ—¥æ±‡æ€»æ•°æ®
        query = text("""
            SELECT 
                COUNT(*) as total_executions,
                SUM(CASE WHEN status = 'success' THEN 1 ELSE 0 END) as successful_executions,
                SUM(CASE WHEN status = 'failed' THEN 1 ELSE 0 END) as failed_executions,
                SUM(CASE WHEN status = 'running' THEN 1 ELSE 0 END) as running_executions,
                AVG(duration) as avg_duration,
                MIN(created_at) as first_execution,
                MAX(created_at) as last_execution
            FROM task_executions 
            WHERE DATE(created_at) = DATE('now')
        """)
        
        result = await self.db.execute(query)
        row = result.first()
        
        if not row or row.total_executions == 0:
            return {
                "total_executions": 0,
                "successful_executions": 0,
                "failed_executions": 0,
                "running_executions": 0,
                "success_rate": 0,
                "avg_duration": 0,
                "first_execution": None,
                "last_execution": None
            }
        
        total = row.total_executions
        success = row.successful_executions or 0
        success_rate = (success / total * 100) if total > 0 else 0
        
        return {
            "total_executions": total,
            "successful_executions": success,
            "failed_executions": row.failed_executions or 0,
            "running_executions": row.running_executions or 0,
            "success_rate": round(success_rate, 2),
            "avg_duration": round(row.avg_duration or 0, 2),
            "first_execution": row.first_execution.isoformat() if row.first_execution else None,
            "last_execution": row.last_execution.isoformat() if row.last_execution else None
        }

    async def get_execution_statistics_by_period(
        self,
        period: str = "day",  # day, week, month
        days: int = 30
    ) -> List[Dict[str, Any]]:
        """
        è·å–æŒ‰æ—¶é—´æ®µçš„æ‰§è¡Œç»Ÿè®¡ï¼ˆå·²ä¼˜åŒ–æ€§èƒ½ï¼‰
        
        ä¼˜åŒ–ç‚¹:
        1. ä½¿ç”¨ DATE() æ›¿ä»£ strftime() æå‡æ€§èƒ½
        2. ä½¿ç”¨ SUM(CASE...) æ›¿ä»£ COUNT(CASE...) æå‡æ•ˆç‡
        3. ç§»é™¤ç¼“å­˜è£…é¥°å™¨ï¼Œç›´æ¥ä¼˜åŒ–æŸ¥è¯¢æœ¬èº«
        
        Args:
            period: ç»Ÿè®¡å‘¨æœŸï¼ˆday/week/monthï¼‰
            days: ç»Ÿè®¡å¤©æ•°
            
        Returns:
            List[Dict[str, Any]]: æ—¶é—´æ®µç»Ÿè®¡æ•°æ®
        """
        since_date = datetime.utcnow() - timedelta(days=days)
        
        # æ ¹æ®å‘¨æœŸé€‰æ‹©æ—¶é—´æ ¼å¼ï¼ˆä¼˜åŒ–åä½¿ç”¨æ›´é«˜æ•ˆçš„å‡½æ•°ï¼‰
        if period == "day":
            # ä½¿ç”¨ DATE() å‡½æ•°ï¼Œæ¯” strftime() å¿« 2-3 å€
            date_expr = "DATE(created_at)"
        elif period == "week":
            # å‘¨ç»Ÿè®¡ä½¿ç”¨ strftimeï¼Œä½†ä¼˜åŒ–æ ¼å¼
            date_expr = "strftime('%Y-W%W', created_at)"
        else:  # month
            # æœˆç»Ÿè®¡ä½¿ç”¨ strftime
            date_expr = "strftime('%Y-%m', created_at)"
        
        # æ„å»ºä¼˜åŒ–åçš„SQLæŸ¥è¯¢
        query = text(f"""
            SELECT 
                {date_expr} as period,
                COUNT(*) as total_tasks,
                SUM(CASE WHEN status = 'success' THEN 1 ELSE 0 END) as success_tasks,
                SUM(CASE WHEN status = 'failed' THEN 1 ELSE 0 END) as failed_tasks,
                AVG(duration) as avg_duration
            FROM task_executions 
            WHERE created_at >= :since_date
            GROUP BY {date_expr}
            ORDER BY period
        """)
        
        result = await self.db.execute(query, {"since_date": since_date})
        
        statistics = []
        for row in result:
            period_str = row.period if row.period else ""
            total = row.total_tasks if row.total_tasks else 0
            success = row.success_tasks if row.success_tasks else 0
            failed = row.failed_tasks if row.failed_tasks else 0
            success_rate = (success / total * 100) if total > 0 else 0
            
            statistics.append({
                "period": period_str,
                "date": period_str,
                "total_tasks": total,
                "success_tasks": success,
                "failed_tasks": failed,
                "success_rate": round(success_rate, 2),
                "average_duration": round(row.avg_duration or 0, 2)
            })
        
        return statistics

    async def get_playbook_execution_stats(
        self,
        days: int = 30,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        è·å–Playbookæ‰§è¡Œç»Ÿè®¡ï¼ˆæŒ‰æ‰§è¡Œæ¬¡æ•°æ’åºï¼Œå·²ä¼˜åŒ–ï¼‰
        
        ä¼˜åŒ–ç‚¹: ä½¿ç”¨ SUM(CASE...) æ›¿ä»£ COUNT(CASE...)
        
        Args:
            days: ç»Ÿè®¡å¤©æ•°
            limit: è¿”å›çš„Playbookæ•°é‡é™åˆ¶
            
        Returns:
            List[Dict[str, Any]]: Playbookæ‰§è¡Œç»Ÿè®¡
        """
        since_date = datetime.utcnow() - timedelta(days=days)
        
        # ä¼˜åŒ–åçš„SQLæŸ¥è¯¢
        query = text("""
            SELECT 
                playbook_name,
                COUNT(*) as total_executions,
                SUM(CASE WHEN status = 'success' THEN 1 ELSE 0 END) as success_executions,
                SUM(CASE WHEN status = 'failed' THEN 1 ELSE 0 END) as failed_executions,
                AVG(duration) as avg_duration,
                MAX(created_at) as last_execution
            FROM task_executions
            WHERE created_at >= :since_date
            GROUP BY playbook_name
            ORDER BY total_executions DESC
            LIMIT :limit
        """)
        
        result = await self.db.execute(query, {"since_date": since_date, "limit": limit})
        
        stats = []
        for row in result:
            success_rate = (row.success_executions / row.total_executions * 100) if row.total_executions > 0 else 0
            
            stats.append({
                "playbook_name": row.playbook_name,
                "total_executions": row.total_executions,
                "success_executions": row.success_executions,
                "failed_executions": row.failed_executions,
                "success_rate": round(success_rate, 2),
                "average_duration": round(row.avg_duration or 0, 2),
                "last_execution": row.last_execution.isoformat() if row.last_execution else None
            })
        
        return stats

    async def get_user_execution_stats(
        self,
        days: int = 30,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        è·å–ç”¨æˆ·æ‰§è¡Œç»Ÿè®¡
        
        Args:
            days: ç»Ÿè®¡å¤©æ•°
            limit: è¿”å›çš„ç”¨æˆ·æ•°é‡é™åˆ¶
            
        Returns:
            List[Dict[str, Any]]: ç”¨æˆ·æ‰§è¡Œç»Ÿè®¡
        """
        since_date = datetime.utcnow() - timedelta(days=days)
        
        # ä½¿ç”¨åŸç”ŸSQLæŸ¥è¯¢ä»¥ç¡®ä¿SQLiteå…¼å®¹æ€§
        query = text("""
            SELECT 
                u.username,
                u.id as user_id,
                COUNT(te.id) as total_executions,
                SUM(CASE WHEN te.status = 'success' THEN 1 ELSE 0 END) as success_executions,
                MAX(te.created_at) as last_execution
            FROM task_executions te
            JOIN users u ON te.user_id = u.id
            WHERE te.created_at >= :since_date
            GROUP BY u.id, u.username
            ORDER BY total_executions DESC
            LIMIT :limit
        """)
        
        result = await self.db.execute(query, {"since_date": since_date, "limit": limit})
        
        stats = []
        for row in result:
            success_rate = (row.success_executions / row.total_executions * 100) if row.total_executions > 0 else 0
            
            stats.append({
                "user_id": row.user_id,
                "username": row.username,
                "total_executions": row.total_executions,
                "success_executions": row.success_executions,
                "success_rate": round(success_rate, 2),
                "last_execution": row.last_execution.isoformat() if row.last_execution else None
            })
        
        return stats

    async def get_execution_trends(self, days: int = 7) -> Dict[str, Any]:
        """
        è·å–æ‰§è¡Œè¶‹åŠ¿æ•°æ®ï¼ˆå·²ä¼˜åŒ–æ€§èƒ½ï¼‰
        
        ä¼˜åŒ–ç‚¹: ç§»é™¤ç¼“å­˜ï¼Œç›´æ¥ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
        
        Args:
            days: åˆ†æå¤©æ•°
            
        Returns:
            Dict[str, Any]: è¶‹åŠ¿æ•°æ®
        """
        since_date = datetime.utcnow() - timedelta(days=days)
        
        # æ¯æ—¥æ‰§è¡Œæ•°é‡è¶‹åŠ¿ï¼ˆå·²ä¼˜åŒ–ï¼‰
        daily_stats = await self.get_execution_statistics_by_period("day", days)
        
        # çŠ¶æ€åˆ†å¸ƒï¼ˆä¼˜åŒ–ï¼šä½¿ç”¨åŸç”ŸSQLä¸€æ¬¡æ€§è·å–ï¼‰
        status_query = text("""
            SELECT 
                status,
                COUNT(*) as count
            FROM task_executions
            WHERE created_at >= :since_date
            GROUP BY status
        """)
        
        status_result = await self.db.execute(status_query, {"since_date": since_date})
        
        status_distribution = {}
        for row in status_result:
            status_distribution[row.status] = row.count
        
        # æ‰§è¡Œæ—¶é•¿åˆ†å¸ƒï¼ˆå·²ä¼˜åŒ–ï¼šä½¿ç”¨ SUM(CASE...)ï¼‰
        duration_query = text("""
            SELECT 
                SUM(CASE WHEN duration <= 60 THEN 1 ELSE 0 END) as under_1min,
                SUM(CASE WHEN duration > 60 AND duration <= 300 THEN 1 ELSE 0 END) as "1_to_5min",
                SUM(CASE WHEN duration > 300 AND duration <= 900 THEN 1 ELSE 0 END) as "5_to_15min",
                SUM(CASE WHEN duration > 900 THEN 1 ELSE 0 END) as over_15min
            FROM task_executions
            WHERE created_at >= :since_date AND duration IS NOT NULL
        """)
        
        duration_result = await self.db.execute(duration_query, {"since_date": since_date})
        duration_row = duration_result.first()
        
        duration_distribution = {
            "under_1min": int(duration_row.under_1min or 0),
            "1_to_5min": int(getattr(duration_row, '1_to_5min', 0) or 0),
            "5_to_15min": int(getattr(duration_row, '5_to_15min', 0) or 0),
            "over_15min": int(duration_row.over_15min or 0)
        }
        
        return {
            "daily_trends": daily_stats,
            "status_distribution": status_distribution,
            "duration_distribution": duration_distribution,
            "analysis_period_days": days
        }

    async def cleanup_old_logs(self, days: int = 90) -> Dict[str, int]:
        """
        æ¸…ç†æ—§çš„æ—¥å¿—æ–‡ä»¶
        
        Args:
            days: ä¿ç•™å¤©æ•°
            
        Returns:
            Dict[str, int]: æ¸…ç†ç»Ÿè®¡ä¿¡æ¯
        """
        cutoff_date = datetime.utcnow() - timedelta(days=days)
        
        # è·å–éœ€è¦æ¸…ç†çš„æ‰§è¡Œè®°å½•
        result = await self.db.execute(
            select(TaskExecution.log_file_path)
            .where(
                and_(
                    TaskExecution.created_at < cutoff_date,
                    TaskExecution.log_file_path.isnot(None),
                    TaskExecution.status.in_([
                        TaskStatus.SUCCESS,
                        TaskStatus.FAILED,
                        TaskStatus.CANCELLED,
                        TaskStatus.TIMEOUT
                    ])
                )
            )
        )
        
        log_files = [row[0] for row in result if row[0]]
        
        deleted_files = 0
        deleted_size = 0
        
        for log_file_path in log_files:
            try:
                if os.path.exists(log_file_path):
                    file_size = os.path.getsize(log_file_path)
                    os.remove(log_file_path)
                    deleted_files += 1
                    deleted_size += file_size
            except Exception:
                continue
        
        return {
            "deleted_files": deleted_files,
            "deleted_size_bytes": deleted_size,
            "deleted_size_mb": round(deleted_size / (1024 * 1024), 2)
        }

    async def export_execution_history(
        self,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        format: str = "json"
    ) -> Dict[str, Any]:
        """
        å¯¼å‡ºæ‰§è¡Œå†å²æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            format: å¯¼å‡ºæ ¼å¼ï¼ˆjson/csvï¼‰
            
        Returns:
            Dict[str, Any]: å¯¼å‡ºçš„æ•°æ®
        """
        query = select(TaskExecution).options(
            selectinload(TaskExecution.user)
        )
        
        conditions = []
        if start_date:
            conditions.append(TaskExecution.created_at >= start_date)
        if end_date:
            conditions.append(TaskExecution.created_at <= end_date)
        
        if conditions:
            query = query.where(and_(*conditions))
        
        query = query.order_by(desc(TaskExecution.created_at))
        
        result = await self.db.execute(query)
        executions = result.scalars().all()
        
        # è½¬æ¢ä¸ºå¯¼å‡ºæ ¼å¼
        export_data = []
        for execution in executions:
            data = {
                "task_id": execution.task_id,
                "playbook_name": execution.playbook_name,
                "status": execution.status.value,
                "user": execution.user.username if execution.user else None,
                "start_time": execution.start_time.isoformat() if execution.start_time else None,
                "end_time": execution.end_time.isoformat() if execution.end_time else None,
                "duration": execution.duration,
                "exit_code": execution.exit_code,
                "created_at": execution.created_at.isoformat(),
                "inventory_targets": execution.inventory_targets
            }
            
            if format == "json":
                # åŒ…å«æ›´å¤šè¯¦ç»†ä¿¡æ¯
                data.update({
                    "extra_vars": execution.extra_vars,
                    "tags": execution.tags,
                    "limit": execution.limit,
                    "result_summary": execution.result_summary,
                    "stats": execution.stats
                })
            
            export_data.append(data)
        
        return {
            "data": export_data,
            "total_records": len(export_data),
            "export_time": datetime.utcnow().isoformat(),
            "format": format
        }

    async def get_host_execution_history(
        self,
        hostname: str,
        limit: int = 5
    ) -> List[TaskExecution]:
        """
        è·å–æŒ‡å®šä¸»æœºçš„æ‰§è¡Œå†å²è®°å½•
        
        Args:
            hostname: ä¸»æœºåæˆ–IPåœ°å€
            limit: é™åˆ¶è¿”å›çš„è®°å½•æ•°
            
        Returns:
            List[TaskExecution]: æ‰§è¡Œå†å²è®°å½•åˆ—è¡¨
        """
        # æ„å»ºæŸ¥è¯¢ï¼Œæœç´¢inventory_targetså­—æ®µä¸­åŒ…å«è¯¥ä¸»æœºåçš„è®°å½•
        query = select(TaskExecution).options(
            selectinload(TaskExecution.user)
        ).where(
            TaskExecution.inventory_targets.ilike(f"%{hostname}%")
        ).order_by(
            desc(TaskExecution.created_at)
        ).limit(limit)
        
        result = await self.db.execute(query)
        executions = result.scalars().all()
        
        return executions
